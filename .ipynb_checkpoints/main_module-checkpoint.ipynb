{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from iapws import IAPWS97\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run class_module_optimization.ipynb\n",
    "%run equations_v2.ipynb\n",
    "%run eq_two_phase.ipynb\n",
    "%run eq_dp_steam.ipynb\n",
    "%run eq_dp_brine.ipynb\n",
    "%run eq_dp.ipynb\n",
    "sys.stdout = open(\"simul_log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Input Data from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import data frame for pipe network;\n",
    "net_df = pd.read_excel('fcrs_in.xls', sheetname = 'network')#2\n",
    "#import data frame for NODE attributes\n",
    "node_df = pd.read_excel('fcrs_in.xls', sheetname= 'nodes')#0\n",
    "#import dataframe for RI pipeline attributes\n",
    "pipe_df = pd.read_excel('fcrs_in.xls', sheetname= 'pipes')#1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pipeline Network Graph; Node and Pipe Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_graph = {}\n",
    "node_dict = {}\n",
    "pipe_dict = {}\n",
    "#Create a graph from nodes; in dictionary format\n",
    "for nodes in range (len(net_df.index)):\n",
    "    nodeID, inlet, outlet, pflow = map(lambda x: net_df.iloc[nodes, x], range(0,4))\n",
    "    network_graph[nodeID] = [inlet, outlet, pflow]\n",
    "\n",
    "for nodes in range(len(node_df.index)):\n",
    "    #create a node class for each row and store it in a dictionary\n",
    "    nodeID,b,c,d,e,f,g,h,i,j,k,l,m,n = map(lambda x: node_df.iloc[nodes, x], range(0,14))\n",
    "    node_dict[nodeID] = node_class(nodeID,b,c,d,e,f,g,h,i,j,k,l,m,n)\n",
    "\n",
    "for pipelines in range(len(pipe_df.index)):\n",
    "    #create a pipeline class for each row and store it in a dictionary\n",
    "    lineID,b,c,d,e,f,g,h,i,j,k,l,m,n  = map(lambda x: pipe_df.iloc[pipelines, x], range(0,14))\n",
    "    pipe_dict[lineID] = pipe_class(lineID,b,c,d,e,f,g,h,i,j,k,l,m,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Phase Flow Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate SF and WF after separator vessel\n",
    "sv_out = two_phase()\n",
    "\n",
    "#sv_link = {'sv7000':['R7000', 'S7000']}\n",
    "sv_link = {'sv3012':['R501', 'S5001'], 'sv3034':['R502', 'S5002'], 'sv3056':['R503', 'S5003'], \\\n",
    "          'sv4012':['R504', 'S5004'], 'sv4034':['R505', 'S5005'], 'sv4050':['R506', 'S5006'], \\\n",
    "          'sv5080':['R508', 'S5008']}\n",
    "\n",
    "for sv in sorted(sv_link):\n",
    "    node_dict[sv_link[sv][0]].p = sv_out[sv][0]\n",
    "    node_dict[sv_link[sv][0]].mf = sv_out[sv][2]\n",
    "    node_dict[sv_link[sv][0]].sio2 = sv_out[sv][3]\n",
    "    node_dict[sv_link[sv][1]].p = sv_out[sv][0]\n",
    "    node_dict[sv_link[sv][1]].mf = sv_out[sv][1]\n",
    "    node_dict[sv_link[sv][1]].co2 = sv_out[sv][4]\n",
    "    node_dict[sv_link[sv][1]].h2s = sv_out[sv][5]\n",
    "    steam = IAPWS97 (P = sv_out[sv][0], x=1)\n",
    "    node_dict[sv_link[sv][0]].t = steam.T-273.15\n",
    "    node_dict[sv_link[sv][1]].t = steam.T-273.15\n",
    "    node_dict[sv_link[sv][0]].calc_ssi()\n",
    "    node_dict[sv_link[sv][1]].calc_ncg()\n",
    "    node_dict[sv_link[sv][1]].ssi = 0\n",
    "    node_dict[sv_link[sv][0]].ncg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow after Separator Vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Create instance of Kf for fittings and insulation params'''\n",
    "kf_list = kf()\n",
    "insul = insulation()\n",
    "\n",
    "for x in sorted(network_graph):\n",
    "    inlet = node_dict[network_graph[x][0]]\n",
    "    outlet = node_dict[network_graph[x][1]]\n",
    "    pipe = pipe_dict[x]\n",
    "    pf = network_graph[x][2]\n",
    "    \n",
    "    if pipe.ID[0] == 'S' and pf != 0:\n",
    "        print('Iterating at ', pipe.ID)\n",
    "        dp_steam(inlet, outlet, pipe, pf)\n",
    "    else:\n",
    "        dp_brine(inlet, outlet, pipe, pf)\n",
    "\n",
    "print(\"run OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Nodes Summary in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = []\n",
    "head = ['nodeID', 'nodeName', 'X', 'Y', 'Pressure', 'Temperature', 'Mass Flow', 'CO2', 'H2S', 'SiO2', 'NCG', 'SSI', 'MWe']\n",
    "\n",
    "for node in sorted(node_dict):\n",
    "    temp = [node_dict[node].ID, node_dict[node].name, node_dict[node].X, node_dict[node].Y, round(node_dict[node].p,2), \\\n",
    "           round(node_dict[node].t,2), \\\n",
    "           round(node_dict[node].mf,3), node_dict[node].co2, node_dict[node].h2s, node_dict[node].sio2,\\\n",
    "           round(node_dict[node].ncg,4), node_dict[node].ssi, round(node_dict[node].mf/2.4,2)]\n",
    "    table.append(temp)\n",
    "\n",
    "df_out = pd.DataFrame(table, columns=head)\n",
    "\n",
    "df_out.to_csv('nodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Pipes Summary in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "head = ['pipeID', 'length', 'total_loss', 'skin_friction', 'fittings_friction', 'heat_loss', 'X', 'Y']\n",
    "\n",
    "for pipe in sorted(pipe_dict):\n",
    "    temp = [ pipe_dict[pipe].ID, pipe_dict[pipe].length, round(pipe_dict[pipe].t_loss,0), pipe_dict[pipe].f_skin, \\\n",
    "            pipe_dict[pipe].f_fit, -pipe_dict[pipe].Q,  pipe_dict[pipe].X, pipe_dict[pipe].Y,]\n",
    "    pipelines.append(temp)\n",
    "\n",
    "df = pd.DataFrame(pipelines, columns=head)\n",
    "\n",
    "df['tot'] = df['skin_friction'] + df['fittings_friction'] + df['heat_loss']\n",
    "df['pskin_friction'] = round(df['skin_friction']/df['tot']*100,0)\n",
    "df['pfittings_friction'] = round(df['fittings_friction']/df['tot']*100,0)\n",
    "df['pheat_loss'] = round(df['heat_loss']/df['tot']*100,0)\n",
    "\n",
    "df.to_csv('pipes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
